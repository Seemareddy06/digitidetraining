{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b5233-c99b-4dc8-8a51-f2826bf9c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "\n",
    "# Sample company policy documents\n",
    "documents = [\n",
    "    \"Refund Policy: We offer a full refund within 30 days of purchase if you are not satisfied with the product.\",\n",
    "    \"To request a refund, please contact customer support with your order details.\",\n",
    "    \"Refunds will be processed within 7 business days.\",\n",
    "    \"Products must be returned in original condition.\"\n",
    "]\n",
    "\n",
    "# Create embeddings and FAISS index\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_texts(documents, embedding_model)\n",
    "\n",
    "# Custom LLM wrapper for OpenRouter API\n",
    "class OpenRouterLLM(LLM, BaseModel):\n",
    "    api_key: str = Field(..., exclude=True)\n",
    "    model_name: str = \"gpt-4o-mini\"\n",
    "    temperature: float = 0.7\n",
    "    max_tokens: int = 150\n",
    "    top_p: float = 0.9\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"openrouter\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            \"top_p\": self.top_p,\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# Instantiate LLM with your OpenRouter API key\n",
    "llm = OpenRouterLLM(api_key=\"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\")\n",
    "\n",
    "# Custom prompt template to combine context and question clearly\n",
    "template = \"\"\"You are a helpful assistant who answers questions based on the company policy excerpt provided.\n",
    "\n",
    "Policy excerpt:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# Create RetrievalQA pipeline with prompt\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# Take user input question\n",
    "question = input(\"Ask a question about the company policy: \")\n",
    "\n",
    "# Run the QA system\n",
    "output = qa.invoke({\"query\": question})\n",
    "\n",
    "answer = output[\"result\"]\n",
    "sources = output.get(\"source_documents\", [])\n",
    "\n",
    "print(\"\\nQuestion:\", question)\n",
    "print(\"Answer:\", answer)\n",
    "print(\"\\nSource document(s):\")\n",
    "for doc in sources:\n",
    "    print(\"-\", doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ec67a-d7e0-413d-b5ed-20217a72bec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (seema)",
   "language": "python",
   "name": "seema"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
